/Users/918839576/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
torch 1.10.1
transformers 4.46.1
accelerate 1.0.1
# of gpus:  1
loading llm model meta-llama/Llama-2-7b-chat-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]
Traceback (most recent call last):
  File "/Users/918839576/Trepo/wanda_replicate/main.py", line 110, in <module>
    main()
  File "/Users/918839576/Trepo/wanda_replicate/main.py", line 59, in main
    tokenizer = AutoTokenizer.from_pretrained(args.model, use_fast=False)
  File "/Users/918839576/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py", line 920, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/Users/918839576/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1651, in __getattribute__
    requires_backends(cls, cls._backends)
  File "/Users/918839576/miniconda3/envs/prune_llm/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1639, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
LlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

